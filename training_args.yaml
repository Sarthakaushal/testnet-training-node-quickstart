# Qwen/Qwen1.5-4B-Chat:
#   per_device_train_batch_size: 1
#   gradient_accumulation_steps: 8
#   num_train_epochs: 1
#   lora_rank: 1
#   lora_alpha: 16
#   lora_dropout: 0.1


# google/gemma-2b:
  # per_device_train_batch_size: 1
  # gradient_accumulation_steps: 8
  # num_train_epochs: 10
  # lora_rank: 4
  # lora_alpha: 8
  # lora_dropout: 0.1


# microsoft/Phi-3.5-mini-instruct:
#   per_device_train_batch_size: 2
#   gradient_accumulation_steps: 8
#   num_train_epochs: 12
#   lora_rank: 2
#   lora_alpha: 32
#   lora_dropout: 0.1

# Qwen/Qwen2.5-3B-Instruct:
#   per_device_train_batch_size: 2
#   gradient_accumulation_steps: 8
#   num_train_epochs: 10
#   lora_rank: 4
#   lora_alpha: 8
#   lora_dropout: 0.1

# srrthk/task-13-microsoft-Phi-3.5-mini-instruct:
#   per_device_train_batch_size: 2
#   gradient_accumulation_steps: 8
#   num_train_epochs: 20
#   lora_rank: 8
#   lora_alpha: 32
#   lora_dropout: 0.1

# # Experiment 3
# microsoft/Phi-3.5-mini-instruct:
#   per_device_train_batch_size: 2
#   gradient_accumulation_steps: 8
#   num_train_epochs: 10
#   lora_rank: 16
#   lora_alpha: 32
#   lora_dropout: 0.05

# # Experiment 4
# microsoft/Phi-3.5-mini-instruct:
#   per_device_train_batch_size: 2
#   gradient_accumulation_steps: 8
#   num_train_epochs: 10
#   lora_rank: 2
#   lora_alpha: 32
#   lora_dropout: 0.1

# # Experiment 5
# microsoft/Phi-3.5-mini-instruct:
#   per_device_train_batch_size: 2
#   gradient_accumulation_steps: 8
#   num_train_epochs: 10
#   lora_rank: 2
#   lora_alpha: 2
#   lora_dropout: 0.05

# # Experiment 6
# microsoft/Phi-3-mini-4k-instruct:
#   per_device_train_batch_size: 2
#   gradient_accumulation_steps: 8
#   num_train_epochs: 6
#   lora_rank: 8
#   lora_alpha: 32
#   lora_dropout: 0.1

# # Experiment 10
# microsoft/Phi-3-mini-4k-instruct:
#   per_device_train_batch_size: 2
#   gradient_accumulation_steps: 8
#   num_train_epochs: 5
#   lora_rank: 8
#   lora_alpha: 32
#   lora_dropout: 0.1

# # Experiment 11
# microsoft/Phi-3-mini-4k-instruct:
#   per_device_train_batch_size: 2
#   gradient_accumulation_steps: 8
#   num_train_epochs: 10
#   lora_rank: 8
#   lora_alpha: 32
#   lora_dropout: 0.1


# # Experiment 12
# microsoft/Phi-3-mini-4k-instruct:
#   per_device_train_batch_size: 2
#   gradient_accumulation_steps: 8
#   num_train_epochs: 12
#   lora_rank: 8
#   lora_alpha: 32
#   lora_dropout: 0.1

# # Experiment 13
# microsoft/Phi-3-mini-4k-instruct:
#   per_device_train_batch_size: 2
#   gradient_accumulation_steps: 8
#   num_train_epochs: 14
#   lora_rank: 8
#   lora_alpha: 32
#   lora_dropout: 0.1

# # Experiment 14
# microsoft/Phi-3-mini-4k-instruct:
#   per_device_train_batch_size: 2
#   gradient_accumulation_steps: 8
#   num_train_epochs: 16
#   lora_rank: 8
#   lora_alpha: 32
#   lora_dropout: 0.1

# # Experiment 15
# microsoft/Phi-3-mini-4k-instruct:
#   per_device_train_batch_size: 2
#   gradient_accumulation_steps: 8
#   num_train_epochs: 18
#   lora_rank: 8
#   lora_alpha: 32
#   lora_dropout: 0.1

# # Experiment 16
# microsoft/Phi-3-mini-4k-instruct:
#   per_device_train_batch_size: 2
#   gradient_accumulation_steps: 8
#   num_train_epochs: 20
#   lora_rank: 8
#   lora_alpha: 32
#   lora_dropout: 0.1

# # Experiment 17
# microsoft/Phi-3-mini-4k-instruct:
#   per_device_train_batch_size: 2
#   gradient_accumulation_steps: 8
#   num_train_epochs: 22
#   lora_rank: 8
#   lora_alpha: 32
#   lora_dropout: 0.1

# Experiment 21
microsoft/Phi-3-mini-4k-instruct:
  per_device_train_batch_size: 2
  gradient_accumulation_steps: 8
  num_train_epochs: 16
  lora_rank: 10
  lora_alpha: 32
  lora_dropout: 0.1

